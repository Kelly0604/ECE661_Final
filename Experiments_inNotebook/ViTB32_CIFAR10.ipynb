{"cells":[{"cell_type":"markdown","metadata":{"id":"dydMncHILOve"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpXKtkG8LQX7"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","from google.colab import drive\n","from tqdm import tqdm\n","from timm import create_model\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{"id":"5v42Sp8bWjky"},"source":["## Mount the Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20578,"status":"ok","timestamp":1733364742813,"user":{"displayName":"Suim Park","userId":"12134455760441715255"},"user_tz":300},"id":"1iaboLESWk8W","outputId":"177748b3-6e09-4fbf-dc1a-54210036384b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Google Drive를 '/content/drive' 경로에 마운트\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLhw70jQireA"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"CpYtJ48ae5fx"},"source":["## CNN and ViT Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176,"referenced_widgets":["c4d41bd611a448fdb0caef99cf4a6e93","fefc46c497444ce78faa725a19918837","f54220fe79c44112993df8ac30efdd3d","2af9222d4bfa4eeeac598021cb4916fd","79c3f5a3cd394b3e8684e1eef1d041fe","8373711c510744c1826cb697502b9702","5a50912b2c62458e88fc6140d7007d8e","fcd6444688a746f4a1b62d041cccb910","6ede56352bc04d4f8b525fe617a2a08c","91a573b13de34bb082bb0e0f6f81388c","301d3fd777e349c391e0c4f9f688f9c2"]},"executionInfo":{"elapsed":12424,"status":"ok","timestamp":1733364755235,"user":{"displayName":"Suim Park","userId":"12134455760441715255"},"user_tz":300},"id":"Hq4pE158ScSE","outputId":"122b450d-e92b-4069-8d16-f6087fb393b5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4d41bd611a448fdb0caef99cf4a6e93","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# ViT-L-16 모델 로드\n","model_vit = create_model('vit_large_patch16_224', pretrained=True)\n","\n","# 모델의 분류 헤드를 원하는 클래스 수로 수정 (예: CIFAR-10 -> 10 클래스)\n","model_vit.head = torch.nn.Linear(model_vit.head.in_features, 10)  # CIFAR-10의 10 클래스\n","\n","# GPU 또는 CPU로 모델 전송\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model_vit = model_vit.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":528,"status":"ok","timestamp":1733364755746,"user":{"displayName":"Suim Park","userId":"12134455760441715255"},"user_tz":300},"id":"Zpv0gvUce9m2","outputId":"98361a0c-a8b6-4945-f204-54d9f4470bc7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 172MB/s]\n"]}],"source":["# ResNet-18 로드 (사전 학습된 가중치 사용)\n","model_cnn = models.resnet18(pretrained=True)\n","\n","# CIFAR-10에 맞게 마지막 분류 계층 수정\n","model_cnn.fc = nn.Linear(model_cnn.fc.in_features, 10)\n","\n","# 모델을 GPU로 이동\n","model_cnn = model_cnn.to(device)"]},{"cell_type":"markdown","metadata":{"id":"WGVEc7LwWCEI"},"source":["## Load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5487,"status":"ok","timestamp":1733364761232,"user":{"displayName":"Suim Park","userId":"12134455760441715255"},"user_tz":300},"id":"wzWkxus7WB3o","outputId":"24245c34-8f3a-42fe-c1f9-b685f714faf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170M/170M [00:01<00:00, 103MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# 데이터셋 전처리\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # ViT에 맞게 크기 조정\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # 정규화\n","])\n","\n","# CIFAR-10 데이터셋 로드\n","train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n","\n","# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1733364761232,"user":{"displayName":"Suim Park","userId":"12134455760441715255"},"user_tz":300},"id":"VlpE_5aSd6Qa","outputId":"7fedb76b-437f-4ea7-9fe5-687a51e483ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training samples: 50000\n","Number of test samples: 10000\n"]}],"source":["# 데이터셋 로드 확인\n","print(f\"Number of training samples: {len(train_dataset)}\")\n","print(f\"Number of test samples: {len(test_dataset)}\")"]},{"cell_type":"markdown","metadata":{"id":"DZEirMCXon7N"},"source":["## Model Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVBscC0QopIC"},"outputs":[],"source":["# 손실 함수와 옵티마이저\n","criterion = nn.CrossEntropyLoss()\n","optimizer_vit = optim.Adam(model_vit.parameters(), lr=0.001)\n","optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqHYcu9torzz"},"outputs":[],"source":["# 학습 함수\n","def train_model(model, optimizer, train_loader, num_epochs=10):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n","\n","        # tqdm으로 학습 상태 표시\n","        batch_progress = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","        for batch_idx, (images, labels) in batch_progress:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            # Backward pass\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # 손실 누적 및 미니 배치 손실 업데이트\n","            running_loss += loss.item()\n","            batch_progress.set_postfix(loss=loss.item())  # tqdm에 손실 표시\n","\n","        # 에포크 종료 후 평균 손실 출력\n","        epoch_loss = running_loss / len(train_loader)\n","        print(f\"Epoch {epoch+1} Completed, Average Loss: {epoch_loss:.4f}\")\n","        print(\"-\" * 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yqxf5J54qplj"},"outputs":[],"source":["model_vit = model_vit.to(device)\n","model_cnn = model_cnn.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Vut7rzVwouCB","outputId":"212d2ff0-659c-4c77-aa62-55c3bbf87ac3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10:\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/10: 100%|██████████| 782/782 [10:30:15<00:00, 48.36s/it, loss=2]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 Completed, Average Loss: 1.9630\n","--------------------------------------------------\n","Epoch 2/10:\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/10:   5%|▍         | 38/782 [32:46<10:41:46, 51.76s/it, loss=1.63]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-14df0950c830>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ViT 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_vit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_vit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# CNN 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-d621ac2dc983>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ViT 학습\n","train_model(model_vit, optimizer_vit, train_loader, num_epochs=10)\n","\n","# CNN 학습\n","train_model(model_cnn, optimizer_cnn, train_loader, num_epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"U-cSJ9rXeJuV"},"source":["## Whitebox Adversarial Attack"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66yHDtOaeNec"},"outputs":[],"source":["def evaluate_white_box(model, attack_fn, data_loader, epsilon, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in data_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # 적대적 예제 생성\n","        adversarial_images = attack_fn(model, images, labels, epsilon)\n","\n","        # 모델 예측\n","        outputs = model(adversarial_images)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    robust_accuracy = 100 * correct / total\n","    print(f\"Robust Accuracy: {robust_accuracy:.2f}%\")\n","    return robust_accuracy"]},{"cell_type":"markdown","metadata":{"id":"xf4kF8-2eScW"},"source":["### Fast Gradient Sign Method (FGSM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKCVu7b3eWuo"},"outputs":[],"source":["def fgsm_attack(model, images, labels, epsilon):\n","    images.requires_grad = True\n","    outputs = model(images)\n","    loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n","    model.zero_grad()\n","    loss.backward()\n","    grad = images.grad.data\n","    perturbed_images = images + epsilon * grad.sign()\n","    perturbed_images = torch.clamp(perturbed_images, 0, 1)\n","    return perturbed_images"]},{"cell_type":"markdown","metadata":{"id":"mLpg8VM6eZqM"},"source":["### Momentum Iterative Method (MIM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCEvso1TeggV"},"outputs":[],"source":["def mim_attack(model, images, labels, epsilon, alpha, iters):\n","    perturbed_images = images.clone().detach()\n","    momentum = torch.zeros_like(images).to(images.device)\n","\n","    for _ in range(iters):\n","        perturbed_images.requires_grad = True\n","        outputs = model(perturbed_images)\n","        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n","        model.zero_grad()\n","        loss.backward()\n","        grad = perturbed_images.grad.data\n","        grad = grad / torch.mean(torch.abs(grad), dim=(1, 2, 3), keepdim=True)\n","        momentum = 0.9 * momentum + grad\n","        perturbed_images = perturbed_images + alpha * momentum.sign()\n","        perturbed_images = torch.clamp(perturbed_images, images - epsilon, images + epsilon)\n","        perturbed_images = torch.clamp(perturbed_images, 0, 1)\n","    return perturbed_images"]},{"cell_type":"markdown","metadata":{"id":"J8tccHBlel19"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAHhBSBSemZn"},"outputs":[],"source":["def evaluate_transferability(source_model, target_model, attack_fn, data_loader, epsilon, device):\n","    source_model.eval()\n","    target_model.eval()\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in data_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # Source 모델에서 적대적 예제 생성\n","        adversarial_images = attack_fn(source_model, images, labels, epsilon)\n","\n","        # Target 모델에서 평가\n","        outputs = target_model(adversarial_images)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    transfer_accuracy = 100 * correct / total\n","    print(f\"Transfer Accuracy: {transfer_accuracy:.2f}%\")\n","    return transfer_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733364761233,"user":{"displayName":"Suim Park","userId":"12134455760441715255"},"user_tz":300},"id":"tA_4rG45i15R","outputId":"41e4f43b-0677-4665-9e02-bd456740923c"},"outputs":[{"name":"stdout","output_type":"stream","text":["|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      |   1200 MiB |   1200 MiB |   1200 MiB |      0 B   |\n","|       from large pool |   1195 MiB |   1195 MiB |   1195 MiB |      0 B   |\n","|       from small pool |      5 MiB |      5 MiB |      5 MiB |      0 B   |\n","|---------------------------------------------------------------------------|\n","| Active memory         |   1200 MiB |   1200 MiB |   1200 MiB |      0 B   |\n","|       from large pool |   1195 MiB |   1195 MiB |   1195 MiB |      0 B   |\n","|       from small pool |      5 MiB |      5 MiB |      5 MiB |      0 B   |\n","|---------------------------------------------------------------------------|\n","| Requested memory      |   1199 MiB |   1199 MiB |   1199 MiB |      0 B   |\n","|       from large pool |   1194 MiB |   1194 MiB |   1194 MiB |      0 B   |\n","|       from small pool |      5 MiB |      5 MiB |      5 MiB |      0 B   |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |   1222 MiB |   1222 MiB |   1222 MiB |      0 B   |\n","|       from large pool |   1216 MiB |   1216 MiB |   1216 MiB |      0 B   |\n","|       from small pool |      6 MiB |      6 MiB |      6 MiB |      0 B   |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |  21760 KiB |  21789 KiB | 440872 KiB | 419112 KiB |\n","|       from large pool |  21120 KiB |  21120 KiB | 436096 KiB | 414976 KiB |\n","|       from small pool |    640 KiB |   2044 KiB |   4776 KiB |   4136 KiB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |     418    |     418    |     418    |       0    |\n","|       from large pool |     105    |     105    |     105    |       0    |\n","|       from small pool |     313    |     313    |     313    |       0    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |     418    |     418    |     418    |       0    |\n","|       from large pool |     105    |     105    |     105    |       0    |\n","|       from small pool |     313    |     313    |     313    |       0    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      78    |      78    |      78    |       0    |\n","|       from large pool |      75    |      75    |      75    |       0    |\n","|       from small pool |       3    |       3    |       3    |       0    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |       6    |       6    |      30    |      24    |\n","|       from large pool |       3    |       3    |      27    |      24    |\n","|       from small pool |       3    |       3    |       3    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n"]}],"source":["# GPU 메모리 초기화\n","torch.cuda.empty_cache()\n","\n","# PyTorch CUDA 메모리 사용량 확인\n","print(torch.cuda.memory_summary(device=None, abbreviated=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"elapsed":618279,"status":"error","timestamp":1733365389803,"user":{"displayName":"Suim Park","userId":"12134455760441715255"},"user_tz":300},"id":"voFuRpgeenL3","outputId":"f2eb49af-6062-4d86-9b71-585770c29b02"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-d4a8b4f7ce98>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Transferability 테스트 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m transferability_vit_to_cnn = evaluate_transferability(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msource_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_vit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mattack_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfgsm_attack\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-e24c4d571987>\u001b[0m in \u001b[0;36mevaluate_transferability\u001b[0;34m(source_model, target_model, attack_fn, data_loader, epsilon, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Source 모델에서 적대적 예제 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0madversarial_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Target 모델에서 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-32a352373a67>\u001b[0m in \u001b[0;36mfgsm_attack\u001b[0;34m(model, images, labels, epsilon)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mperturbed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Transferability 테스트 실행\n","transferability_vit_to_cnn = evaluate_transferability(\n","    source_model=model_vit,\n","    target_model=model_cnn,\n","    attack_fn=fgsm_attack,\n","    data_loader=test_loader,\n","    epsilon=0.03,\n","    device=device\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOFi7439PyAyBMsxsk1Pgx4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2af9222d4bfa4eeeac598021cb4916fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91a573b13de34bb082bb0e0f6f81388c","placeholder":"​","style":"IPY_MODEL_301d3fd777e349c391e0c4f9f688f9c2","value":" 1.22G/1.22G [00:05&lt;00:00, 230MB/s]"}},"301d3fd777e349c391e0c4f9f688f9c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a50912b2c62458e88fc6140d7007d8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ede56352bc04d4f8b525fe617a2a08c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79c3f5a3cd394b3e8684e1eef1d041fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8373711c510744c1826cb697502b9702":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91a573b13de34bb082bb0e0f6f81388c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4d41bd611a448fdb0caef99cf4a6e93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fefc46c497444ce78faa725a19918837","IPY_MODEL_f54220fe79c44112993df8ac30efdd3d","IPY_MODEL_2af9222d4bfa4eeeac598021cb4916fd"],"layout":"IPY_MODEL_79c3f5a3cd394b3e8684e1eef1d041fe"}},"f54220fe79c44112993df8ac30efdd3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcd6444688a746f4a1b62d041cccb910","max":1217334682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ede56352bc04d4f8b525fe617a2a08c","value":1217334682}},"fcd6444688a746f4a1b62d041cccb910":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fefc46c497444ce78faa725a19918837":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8373711c510744c1826cb697502b9702","placeholder":"​","style":"IPY_MODEL_5a50912b2c62458e88fc6140d7007d8e","value":"model.safetensors: 100%"}}}}},"nbformat":4,"nbformat_minor":0}